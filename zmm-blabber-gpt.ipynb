{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPldhhYpKGr6j9T/A8zjNjv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/mount40/zmm-blabber/refs/heads/main/data/zmm.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pR9t4W6Gd1qo","executionInfo":{"status":"ok","timestamp":1753186348064,"user_tz":-180,"elapsed":339,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}},"outputId":"891febcc-9c3e-4ceb-adff-b3fc6250c909"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-07-22 12:12:32--  https://raw.githubusercontent.com/mount40/zmm-blabber/refs/heads/main/data/zmm.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 793748 (775K) [text/plain]\n","Saving to: ‘zmm.txt.1’\n","\n","\rzmm.txt.1             0%[                    ]       0  --.-KB/s               \rzmm.txt.1           100%[===================>] 775.14K  --.-KB/s    in 0.04s   \n","\n","2025-07-22 12:12:33 (19.2 MB/s) - ‘zmm.txt.1’ saved [793748/793748]\n","\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","torch.manual_seed(28)\n","\n","# hyperparameters\n","batch_size = 64\n","block_size = 256\n","max_iters = 5000\n","eval_interval = 300\n","learning_rate = 3e-4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","eval_iters = 200\n","n_embed = 384\n","n_head = 6\n","n_layer = 6\n","dropout = 0.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-12ZhRLXd3wa","executionInfo":{"status":"ok","timestamp":1753186348092,"user_tz":-180,"elapsed":24,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}},"outputId":"b00f5c0b-ceb4-4366-df4f-ea1b6747e918"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["with open(\"zmm.txt\", \"r\") as f:\n","  text = f.read()\n","\n","print(\"dataset length: \", len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVAdK4zHd8E3","executionInfo":{"status":"ok","timestamp":1753186348109,"user_tz":-180,"elapsed":9,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}},"outputId":"404b866a-ab28-41d6-8f72-42dc827101f6"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset length:  793748\n"]}]},{"cell_type":"code","source":["chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(vocab_size)\n","\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [ stoi[c] for c in s ] # encoder: take a string, output a list of integers\n","decode = lambda l: ''.join([ itos[i] for i in l ]) # decoder: take a list of integers, output a string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ql3jGl-leBSQ","executionInfo":{"status":"ok","timestamp":1753186348232,"user_tz":-180,"elapsed":106,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}},"outputId":"ef199782-806b-40de-88f3-6112d60ab33c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["80\n"]}]},{"cell_type":"code","source":["data = torch.tensor(encode(text), dtype=torch.long)\n","n = int(0.9 * len(data))\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"id":"DF0ggmGXeIH6","executionInfo":{"status":"ok","timestamp":1753186348252,"user_tz":-180,"elapsed":26,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def get_batch(split):\n","  data = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i:i + block_size] for i in ix])\n","  y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n","  x, y = x.to(device), y.to(device)\n","  return x, y"],"metadata":{"id":"2o1CXPGueMZy","executionInfo":{"status":"ok","timestamp":1753186348259,"user_tz":-180,"elapsed":4,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def estimate_loss():\n","  out = {}\n","  model.eval()\n","  for split in ['train', 'val']:\n","    losses = torch.zeros(eval_iters)\n","    for k in range(eval_iters):\n","      X, Y = get_batch(split)\n","      logits, loss = model(X, Y)\n","      losses[k] = loss.item()\n","    out[split] = losses.mean()\n","  model.train()\n","  return out"],"metadata":{"id":"1feRnU48eiIv","executionInfo":{"status":"ok","timestamp":1753186348277,"user_tz":-180,"elapsed":4,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class AttentionHead(nn.Module):\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embed, head_size, bias=False)\n","    self.query = nn.Linear(n_embed, head_size, bias=False)\n","    self.value = nn.Linear(n_embed, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","  def forward(self, x):\n","    B, T, C = x.shape\n","    k = self.key(x)\n","    q = self.query(x)\n","    wei = q @ k.transpose(-2, -1) * C ** -0.5\n","    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","    wei = F.softmax(wei, dim=-1)\n","    v = self.value(x)\n","    out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","    return out"],"metadata":{"id":"IyOBipG-3MWs","executionInfo":{"status":"ok","timestamp":1753186348283,"user_tz":-180,"elapsed":2,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"1ZwA4F9fLiYg"}},{"cell_type":"code","source":["class MultiHeadAttentionHead(nn.Module):\n","  def __init__(self, num_heads, head_size):\n","    super().__init__()\n","    self.heads = nn.ModuleList([AttentionHead(head_size) for _ in range(num_heads)])\n","    self.proj = nn.Linear(n_embed, n_embed)\n","\n","  def forward(self, x):\n","    out = torch.cat([h(x) for h in self.heads], dim=-1)\n","    out = self.proj(out)\n","    return out"],"metadata":{"id":"y98eKRHX5ZKL","executionInfo":{"status":"ok","timestamp":1753186348299,"user_tz":-180,"elapsed":3,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","  def __init__(self, n_embed):\n","    super().__init__()\n","    self.net = nn.Sequential(\n","      nn.Linear(n_embed, 4 * n_embed),\n","      nn.ReLU(),\n","      nn.Linear(4 * n_embed, n_embed),\n","      nn.Dropout(dropout),\n","    )\n","\n","  def forward(self, x):\n","    return self.net(x)"],"metadata":{"id":"YI1M5Mob6ON4","executionInfo":{"status":"ok","timestamp":1753186348325,"user_tz":-180,"elapsed":23,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# grouping attention multi-heads with feed-forward nets, so that we can have both more multi-heads and a corresponding feed-forward net for each of the heads tightly grouped together\n","class Block(nn.Module):\n","  def __init__(self, n_embed, n_head):\n","    super().__init__()\n","    head_size = n_embed // n_head\n","    self.attention_heads = MultiHeadAttentionHead(n_head, head_size)\n","    self.feed_forward_net = FeedForward(n_embed)\n","    self.layer_norm1 = nn.LayerNorm(n_embed)\n","    self.layer_norm2 = nn.LayerNorm(n_embed)\n","\n","  def forward(self, x):\n","    x = x + self.attention_heads(self.layer_norm1(x))\n","    x = x + self.feed_forward_net(self.layer_norm2(x))\n","    return x"],"metadata":{"id":"TJUOqdEW7fG4","executionInfo":{"status":"ok","timestamp":1753186348326,"user_tz":-180,"elapsed":22,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class GPTLanguageModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # each token directly reads off the logits for the next token from a lookup table\n","    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n","    self.position_embedding_table = nn.Embedding(block_size, n_embed)\n","    self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head) for _ in range(n_layer)])\n","    self.layer_norm = nn.LayerNorm(n_embed) # final layer norm\n","    self.lm_head = nn.Linear(n_embed, vocab_size)\n","\n","  def forward(self, idx, targets=None):\n","    B, T = idx.shape\n","\n","    # idx and targets are both (B, T) tensor of integers\n","    token_embeddings = self.token_embedding_table(idx) # (B, T, C)\n","    pos_embeddings = self.position_embedding_table(torch.arange(T, device=device)) # (T, C)\n","    x = token_embeddings + pos_embeddings # (B, T, C)\n","    x = self.blocks(x) # (B,T,C)\n","    x = self.layer_norm(x) # (B,T,C)\n","    logits = self.lm_head(x) # (B,T,vocab_size)\n","\n","    if targets is None:\n","      loss = None\n","    else:\n","      B, T, C = logits.shape\n","      logits = logits.view(B * T, C)\n","      targets = targets.view(B * T)\n","      loss = F.cross_entropy(logits, targets)\n","\n","    return logits, loss\n","\n","  def generate(self, idx, max_new_tokens):\n","    # idx is (B, T) array of indices in the current context\n","    for _ in range(max_new_tokens):\n","      idx_cond = idx[:, -block_size:]\n","      # get the predictions\n","      logits, loss = self(idx_cond)\n","      # focus only on the last time step\n","      logits = logits[:, -1, :] # becomes (B, C)\n","      # apply softmax to get probabilities\n","      probs = F.softmax(logits, dim=-1) # (B, C)\n","      # sample from the distribution\n","      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","      # append sampled index to the running sequence\n","      idx = torch.cat((idx, idx_next), dim=1) # (B, T + 1)\n","    return idx\n"],"metadata":{"id":"T3CxwkU8e95K","executionInfo":{"status":"ok","timestamp":1753186348327,"user_tz":-180,"elapsed":20,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model = BigramLanguageModel()\n","m = model.to(device)"],"metadata":{"id":"azvnr2FufHDK","executionInfo":{"status":"ok","timestamp":1753186348423,"user_tz":-180,"elapsed":103,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"],"metadata":{"id":"bLke-k-ufMGk","executionInfo":{"status":"ok","timestamp":1753186348438,"user_tz":-180,"elapsed":30,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["for iter in range(max_iters):\n","  if iter % eval_interval == 0:\n","    losses = estimate_loss()\n","    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","  if iter % eval_interval == 0 or iter == max_iters - 1:\n","    losses = estimate_loss()\n","    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","  xb, yb = get_batch('train')\n","\n","  logits, loss = model(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()"],"metadata":{"id":"rAmuMZ_zfZ8P","executionInfo":{"status":"ok","timestamp":1753191152314,"user_tz":-180,"elapsed":4803893,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}},"outputId":"0ace1710-801b-403f-b148-cf62fc29f5f6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["step 0: train loss 4.5447, val loss 4.5410\n","step 0: train loss 4.5446, val loss 4.5416\n","step 300: train loss 2.3417, val loss 2.3363\n","step 300: train loss 2.3437, val loss 2.3359\n","step 600: train loss 1.7810, val loss 1.8114\n","step 600: train loss 1.7837, val loss 1.8129\n","step 900: train loss 1.5223, val loss 1.5825\n","step 900: train loss 1.5242, val loss 1.5830\n","step 1200: train loss 1.3843, val loss 1.4789\n","step 1200: train loss 1.3863, val loss 1.4785\n","step 1500: train loss 1.2986, val loss 1.4235\n","step 1500: train loss 1.2964, val loss 1.4229\n","step 1800: train loss 1.2306, val loss 1.3925\n","step 1800: train loss 1.2313, val loss 1.3912\n","step 2100: train loss 1.1684, val loss 1.3733\n","step 2100: train loss 1.1691, val loss 1.3754\n","step 2400: train loss 1.1149, val loss 1.3772\n","step 2400: train loss 1.1164, val loss 1.3749\n","step 2700: train loss 1.0670, val loss 1.3824\n","step 2700: train loss 1.0672, val loss 1.3819\n","step 3000: train loss 1.0096, val loss 1.4004\n","step 3000: train loss 1.0109, val loss 1.4051\n","step 3300: train loss 0.9472, val loss 1.4299\n","step 3300: train loss 0.9497, val loss 1.4307\n","step 3600: train loss 0.8903, val loss 1.4725\n","step 3600: train loss 0.8899, val loss 1.4724\n","step 3900: train loss 0.8265, val loss 1.5226\n","step 3900: train loss 0.8262, val loss 1.5222\n","step 4200: train loss 0.7526, val loss 1.5939\n","step 4200: train loss 0.7553, val loss 1.5941\n","step 4500: train loss 0.6863, val loss 1.6752\n","step 4500: train loss 0.6852, val loss 1.6807\n","step 4800: train loss 0.6137, val loss 1.7788\n","step 4800: train loss 0.6151, val loss 1.7727\n","step 4999: train loss 0.5688, val loss 1.8343\n"]}]},{"cell_type":"code","source":["# generate\n","context = torch.zeros((1, 1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"],"metadata":{"id":"59Ytp6xjfr38","executionInfo":{"status":"ok","timestamp":1753191460999,"user_tz":-180,"elapsed":170687,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}},"outputId":"4f317338-e234-40af-a717-cb0114699931","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","says, ``South no one would acepl't this not stub to this way...not\n","completely its overall...to understand its quite somewhat down anyway....with\n","auside...what good of classically to who had identified it for many\n","killeing times I've individual practical our world you know now that produced\n","the machine. Chris is always kill about what he said that Phdrus saw in\n","the most doors of the kids better. Mathematics knew who occur with no graduation who\n","has worked one's way of contains through the cottonwooks is problem.\n","It's an important now to talk to still back and it for Jus looking from\n","whether Nature to Phdrus that trunk is property. It's growing and work on it with\n","him, hold occur to original and it should be known to inca what they have been\n","having a little boy damn agot, much not to send with many particular\n","with both of a motorcycle maintenance be one-zero. Only church at has\n","a needed by the nineteen-that of the machine. The maalted is cross. Few\n","in reason. I've simple with the second difference hard striking between\n","people who have all been understady to a deep boot political or book. I\n","can and esthetic writer the part is deep, having his limited to be listened\n","and alted his nibrertay. We are out on two hard metaphysical more\n","social hands. And unless you do it. But never simply your special\n","how to know this whole mountains or up to it. The night way of\n","departs of internal terity to stay are some of what your desires process duagan. I do know\n","inten? Why didn't the work you see anything in a thing. It tas was a natical\n","home. My writer is part of his cyclist of Plato UAMssian\n","identity in the world but as reality objectivity. For me for\n","wall but on the world came up into his not parts. At the ogether and see them was\n","a mistake. Diale...mild...He beauty her the imtal for paties. Big left it found it\n","into a format traditional empirical values, has its usually born dailed. The\n","solution doesn't sense of pacer in Montened work and I comment it on\n","are at one tip and only turn them in she hands. As we do\n","trouble this you were made. It had the essence waves the materials that we\n","done doesn't.\n","24\n","\n","\n","At first Phdrus understands the narrow legal is now. Have he reternal thinks\n","which seems presumptive for permittents. He meant by the DeWeeses are\n","not many meaning or Quality had objecte was the started logums of\n","as cleep bad because other things he had shifted talking in a whole craping\n","just way.\n","After the students had liquid began to find out that with an answer satiscional\n","to elimination. But Did any For mechanic at me fist. There's no phenomenon of\n","substanting consists in one of his can administration society. And planned\n","admistical, named idea to provide a ``holy other.'' The estheticians cause they\n","were discovered with psolute. The viewpoint hang also telling them you've\n","completed you wander at these anttisfies one perceives. Euclid's just often\n","physical scientists had proped that experience. Tr him to experiment hy? Phdrus\n","could still discuss that the admit statements were spattion of an incompetence. If\n","doubling that seems to be until the Greeks thought the whole nexistic edistity\n","for a resign consciousness. They discover have been for purpose and technological\n","machine as perhapace. For me more ``Zen,'' a philosophic science and an invention. Per\n","``Dointagon.'' The said the Substance doesn't come to that these born\n","nature's going or suth to go organ and see that one realizes to person to\n","31\n","\n","\n","understand that a narrow is to destroy the whole world all around the\n","ghosts is demonstrator to legup and then about ``Sylvia'' time to\n","``Yes!'' Then you shake to see.\n","She had been almost blowed by the water and members Moses and the\n","immortal Partistic Gods into peace of mind of thought. Yet us even\n","more right them as ``they'' as lot one understood what you can see. And that\n","So is avoidantly the grades was an inner principated or gear but the\n","system. You don't understand them, so that you have to done is quite more staying,\n","the split ittle so case we act you ou a reality. Sure of John and\n","Sylvia ent, the throw your cycle here we doing what you were over. The result in\n","gumption mathesery years of fresh and there are some change apparent when\n","craftsmanlighten came in his experimental poor work, sitting things that are\n","inventions. What they said was truly existing for nature or selects I move\n","have been seen mind and branches upon the surroundings of standar.\n","We talk stunts at strange boxes ; when perhaps in Greecefully phases\n","in phase, where he starved, had would have done this expression to the same\n","technologists would be constituted by so can of a demotely\n","that should be Quality do not exist. The world be a stuber can always\n","missing watching into doesn't law of gravity. Everything is the worst going\n","or to come ap) both lecture and tell him down to enter his fact he art.\n","``Not other things came with his reason havily never having anything\n","which Pposts called it as a manify of one of cealing statements are\n","on any time. He goes on another knowledge. Chris reumed up ferver, but it seems completely\n","different direction other thousands in so he could turn the so follow philosophers\n","would have been found in something the machine and incompanished of odding and\n","from Quality to his pre-Relativity was probably in the American resortad has been so\n","both we move appled in type of mills but nor valves. Not even chalk we spatter arguments\n","of his own knowledge around we have shifted as a result of a train. For me\n","through the most important of art is not a number of time. Considert seems as the partmitter.\n","The patroport of what he is settled in suddenly as he wrote it on his motorcycle\n","material, which prettiness has no was going to fulfing there. Cold\n","majone to bring a bridger of Quality. But that isn't, the sand looked less right,\n","then throttle  and scrawns are right. Beyond when they are fantainhtily feed\n","too.\n","I'm mad thinking it other mystic shopped he takes a ``principle'' seemed\n","out into bad. They spell could take up one to heat noise. But that they could\n","attitude is bequited a Quality for hunas they don't, when they value t questions because\n","what is serious. Another mumble of your might senses. The majority of\n","things causes to fast ask the world with enomong of gumption if its\n","composed to to work with methods other of work. Back or forgotten so tune\n","loneliness in the selection seems to get something more and those reasonings\n","through a porcelar of towns that fold and had a man styliff town\n","satem in hero, and this search of subject-object maybe because has meant head of\n","taken the whole studies. Plato's more commuted arguid.\n","``Why are the worst?'' Now, a smissing of photor breathesion, an esthetician\n","crosed to dething a little exture or object that last neither some\n","92\n","\n","\n","\n","must he knew working concrete he talked about child-take trip on top. He\n","hands and white small in his spirit took plencion there is no good can.\n","It begins to do be to see the time money thought of the door now. I haven't breakth\n","of the house, the whole thing to be pointing to work the immediate statement of\n","the Church of Reason. If you try to ``Art Pson't double that\n","mind. It don't many times it I want to be talk about another road turn into\n","that mu without thought they were nervous, the woodeness.\n","Chris lies games it got into this hypocritized. It's another work. We talked\n","about was not a big tablet which probably are construct\n","to boredom both (-this second philosopher in his face. I don't think he can't get\n","on another real understanding of Quality. It was all to stuck on a cycle where ``sky.''\n","This is job. He probably is just like anything else. And the memory lu of\n","science, but fine as the noist work as we are also a time before. Later I won't. It\n","wonder forth of coffee. And so that search him for years and hat was\n","shering in a way abstraction says philosophy. These reasonings. Poincar was\n","not constitute, an antion how the brick beson he doesn't missing for me\n","through but he sees in it, but Ellenger, senses. I'm not quite sometimes still striked by it\n","other temperature with the same thing job. You folk from him the primary\n","goes for all the problems of metal is not so much attiture.\n","Anote now, but the job different for what seems to be cause of\n","the subject for a person would. Then another path modes of\n","reality in the suddenly by the word of which Aristotle teaching in the\n","mirror of according to hand a cold on the engine. Cauty.\n","37\n","\n","\n","The grop is nowhere beer. And fatter favor me to see that the grows had been restired\n","to apparently going by stuckness is silent.\n","202\n","\n","\n","Go to the saw of nice would apply gree. These overall paths awapeness of\n","identity and painting of gravity. It can be defined a long hard a new finisher causease of\n","responsions, at about the ability to solve or formal scientific excispelly in hunti-timical\n","scientists were desires that would destroy the eternal prof technics but the\n","proportion would seek to fall of the material attentitude to achieve certaint. What you're\n","``stwere,'' is making to the motorcycle that people experience were bond.\n","At examine time, to see things that comes from an infunation of the intensity\n","of test in within this statements. But whenever the Euclidian geometry wrom\n","seems to understand political or duty, that which discouses contributes to be\n","temperature t. But that, I do now, but that Bill mohose he had no practical\n","Purpose is Quality inreal order. He had recorded and restit tests but\n","the time sense and has no warning and what metal had gotten to be a desert part of bots\n","but to our pack a jourping water and terribly a long change between\n","might and to the footpat of his own sanity and absolutely and\n","art freedom by hundred patience. And their reality of sculpture, and\n","precision motorcycle before Reason. In his cose he muse boys mu\n","senses, he used John and Sylvia an is the shauted of the Misson as he pointment in the\n","Church of Reason, the Professor were just a part of anistipation wipe-ad-one\n","shakists with tended to run freeway.\n","Both state\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I8fD1x43Cw_c","executionInfo":{"status":"ok","timestamp":1753191236948,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vasilen Alexandrov","userId":"15871981788963914562"}}},"execution_count":34,"outputs":[]}]}